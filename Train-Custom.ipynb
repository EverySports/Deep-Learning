{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Library & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random, os, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>l ankle_X</th>\n",
       "      <th>l ankle_Y</th>\n",
       "      <th>r knee_X</th>\n",
       "      <th>r knee_Y</th>\n",
       "      <th>r hip_X</th>\n",
       "      <th>r hip_Y</th>\n",
       "      <th>pelvis_X</th>\n",
       "      <th>pelvis_Y</th>\n",
       "      <th>r ankle_X</th>\n",
       "      <th>r ankle_Y</th>\n",
       "      <th>l hip_X</th>\n",
       "      <th>l hip_Y</th>\n",
       "      <th>l knee_X</th>\n",
       "      <th>l knee_Y</th>\n",
       "      <th>spine_X</th>\n",
       "      <th>spine_Y</th>\n",
       "      <th>thorax_X</th>\n",
       "      <th>thorax_Y</th>\n",
       "      <th>upper neck_X</th>\n",
       "      <th>upper neck_Y</th>\n",
       "      <th>head top_X</th>\n",
       "      <th>head top_Y</th>\n",
       "      <th>r shoulder_X</th>\n",
       "      <th>r shoulder_Y</th>\n",
       "      <th>r elbow_X</th>\n",
       "      <th>r elbow_Y</th>\n",
       "      <th>r wrist_X</th>\n",
       "      <th>r wrist_Y</th>\n",
       "      <th>l wrist_X</th>\n",
       "      <th>l wrist_Y</th>\n",
       "      <th>l elbow_X</th>\n",
       "      <th>l elbow_Y</th>\n",
       "      <th>l shoulder_X</th>\n",
       "      <th>l shoulder_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/01560...</td>\n",
       "      <td>656</td>\n",
       "      <td>231</td>\n",
       "      <td>616</td>\n",
       "      <td>269</td>\n",
       "      <td>573</td>\n",
       "      <td>185</td>\n",
       "      <td>610</td>\n",
       "      <td>187</td>\n",
       "      <td>620</td>\n",
       "      <td>394</td>\n",
       "      <td>647</td>\n",
       "      <td>188</td>\n",
       "      <td>661</td>\n",
       "      <td>221</td>\n",
       "      <td>651</td>\n",
       "      <td>203</td>\n",
       "      <td>647</td>\n",
       "      <td>176</td>\n",
       "      <td>637.0201</td>\n",
       "      <td>189.8183</td>\n",
       "      <td>695.9799</td>\n",
       "      <td>108.1817</td>\n",
       "      <td>601</td>\n",
       "      <td>167</td>\n",
       "      <td>553</td>\n",
       "      <td>161</td>\n",
       "      <td>606</td>\n",
       "      <td>217</td>\n",
       "      <td>688</td>\n",
       "      <td>313</td>\n",
       "      <td>693</td>\n",
       "      <td>240</td>\n",
       "      <td>692</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/01559...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>806</td>\n",
       "      <td>543</td>\n",
       "      <td>763</td>\n",
       "      <td>568</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>720</td>\n",
       "      <td>593</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>341</td>\n",
       "      <td>144</td>\n",
       "      <td>683</td>\n",
       "      <td>290</td>\n",
       "      <td>682.0000</td>\n",
       "      <td>256.0000</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>68.0000</td>\n",
       "      <td>647</td>\n",
       "      <td>281</td>\n",
       "      <td>555</td>\n",
       "      <td>410</td>\n",
       "      <td>563</td>\n",
       "      <td>296</td>\n",
       "      <td>545</td>\n",
       "      <td>466</td>\n",
       "      <td>711</td>\n",
       "      <td>516</td>\n",
       "      <td>719</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/00580...</td>\n",
       "      <td>883</td>\n",
       "      <td>707</td>\n",
       "      <td>816</td>\n",
       "      <td>510</td>\n",
       "      <td>908</td>\n",
       "      <td>438</td>\n",
       "      <td>974</td>\n",
       "      <td>446</td>\n",
       "      <td>804</td>\n",
       "      <td>711</td>\n",
       "      <td>1040</td>\n",
       "      <td>454</td>\n",
       "      <td>906</td>\n",
       "      <td>528</td>\n",
       "      <td>934</td>\n",
       "      <td>480</td>\n",
       "      <td>985</td>\n",
       "      <td>253</td>\n",
       "      <td>982.7591</td>\n",
       "      <td>235.9694</td>\n",
       "      <td>962.2409</td>\n",
       "      <td>80.0306</td>\n",
       "      <td>902</td>\n",
       "      <td>253</td>\n",
       "      <td>798</td>\n",
       "      <td>340</td>\n",
       "      <td>869</td>\n",
       "      <td>214</td>\n",
       "      <td>1142</td>\n",
       "      <td>478</td>\n",
       "      <td>1167</td>\n",
       "      <td>353</td>\n",
       "      <td>1067</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/08661...</td>\n",
       "      <td>331</td>\n",
       "      <td>455</td>\n",
       "      <td>305</td>\n",
       "      <td>375</td>\n",
       "      <td>201</td>\n",
       "      <td>340</td>\n",
       "      <td>248</td>\n",
       "      <td>341</td>\n",
       "      <td>301</td>\n",
       "      <td>461</td>\n",
       "      <td>294</td>\n",
       "      <td>342</td>\n",
       "      <td>335</td>\n",
       "      <td>370</td>\n",
       "      <td>305</td>\n",
       "      <td>359</td>\n",
       "      <td>279</td>\n",
       "      <td>263</td>\n",
       "      <td>277.0210</td>\n",
       "      <td>268.7786</td>\n",
       "      <td>305.9790</td>\n",
       "      <td>184.2214</td>\n",
       "      <td>244</td>\n",
       "      <td>261</td>\n",
       "      <td>260</td>\n",
       "      <td>335</td>\n",
       "      <td>328</td>\n",
       "      <td>354</td>\n",
       "      <td>362</td>\n",
       "      <td>346</td>\n",
       "      <td>327</td>\n",
       "      <td>320</td>\n",
       "      <td>314</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/06011...</td>\n",
       "      <td>881</td>\n",
       "      <td>349</td>\n",
       "      <td>896</td>\n",
       "      <td>318</td>\n",
       "      <td>865</td>\n",
       "      <td>248</td>\n",
       "      <td>904</td>\n",
       "      <td>237</td>\n",
       "      <td>980</td>\n",
       "      <td>322</td>\n",
       "      <td>943</td>\n",
       "      <td>226</td>\n",
       "      <td>948</td>\n",
       "      <td>290</td>\n",
       "      <td>869</td>\n",
       "      <td>242</td>\n",
       "      <td>858</td>\n",
       "      <td>135</td>\n",
       "      <td>871.1877</td>\n",
       "      <td>180.4244</td>\n",
       "      <td>835.8123</td>\n",
       "      <td>58.5756</td>\n",
       "      <td>792</td>\n",
       "      <td>147</td>\n",
       "      <td>754</td>\n",
       "      <td>247</td>\n",
       "      <td>772</td>\n",
       "      <td>294</td>\n",
       "      <td>961</td>\n",
       "      <td>223</td>\n",
       "      <td>995</td>\n",
       "      <td>163</td>\n",
       "      <td>923</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NAME  l ankle_X  l ankle_Y  \\\n",
       "0  ../../Datasets/mpii_human_pose_v1/images/01560...        656        231   \n",
       "1  ../../Datasets/mpii_human_pose_v1/images/01559...         -1         -1   \n",
       "2  ../../Datasets/mpii_human_pose_v1/images/00580...        883        707   \n",
       "3  ../../Datasets/mpii_human_pose_v1/images/08661...        331        455   \n",
       "4  ../../Datasets/mpii_human_pose_v1/images/06011...        881        349   \n",
       "\n",
       "   r knee_X  r knee_Y  r hip_X  r hip_Y  pelvis_X  pelvis_Y  r ankle_X  \\\n",
       "0       616       269      573      185       610       187        620   \n",
       "1        -1        -1      806      543       763       568         -1   \n",
       "2       816       510      908      438       974       446        804   \n",
       "3       305       375      201      340       248       341        301   \n",
       "4       896       318      865      248       904       237        980   \n",
       "\n",
       "   r ankle_Y  l hip_X  l hip_Y  l knee_X  l knee_Y  spine_X  spine_Y  \\\n",
       "0        394      647      188       661       221      651      203   \n",
       "1         -1      720      593        -1        -1      341      144   \n",
       "2        711     1040      454       906       528      934      480   \n",
       "3        461      294      342       335       370      305      359   \n",
       "4        322      943      226       948       290      869      242   \n",
       "\n",
       "   thorax_X  thorax_Y  upper neck_X  upper neck_Y  head top_X  head top_Y  \\\n",
       "0       647       176      637.0201      189.8183    695.9799    108.1817   \n",
       "1       683       290      682.0000      256.0000    676.0000     68.0000   \n",
       "2       985       253      982.7591      235.9694    962.2409     80.0306   \n",
       "3       279       263      277.0210      268.7786    305.9790    184.2214   \n",
       "4       858       135      871.1877      180.4244    835.8123     58.5756   \n",
       "\n",
       "   r shoulder_X  r shoulder_Y  r elbow_X  r elbow_Y  r wrist_X  r wrist_Y  \\\n",
       "0           601           167        553        161        606        217   \n",
       "1           647           281        555        410        563        296   \n",
       "2           902           253        798        340        869        214   \n",
       "3           244           261        260        335        328        354   \n",
       "4           792           147        754        247        772        294   \n",
       "\n",
       "   l wrist_X  l wrist_Y  l elbow_X  l elbow_Y  l shoulder_X  l shoulder_Y  \n",
       "0        688        313        693        240           692           185  \n",
       "1        545        466        711        516           719           299  \n",
       "2       1142        478       1167        353          1067           253  \n",
       "3        362        346        327        320           314           264  \n",
       "4        961        223        995        163           923           123  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_ROOT_PATH = f'../../Datasets/mpii_human_pose_v1'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ = pd.read_csv(TRAIN_ROOT_PATH + f'/mpii_human_pose_v1_u12_2/mpii_dataset.csv')\n",
    "df_ = df_.iloc[:, 1:-3]\n",
    "df_ = df_.iloc[:, [0, 13, 14, 5, 6, 3, 4, 1, 2, 7, 8, 9, 10, 11, 12,\n",
    "                  15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 32, 25, 26, 23, 24, 21, 22]]\n",
    "spine = (np.array(df_.iloc[:, [13, 14]]) +  np.array(df_.iloc[:, [15, 16]])) // 2\n",
    "df_ = pd.concat([df_, pd.DataFrame(spine)], axis=1)\n",
    "df = df_.iloc[:, [0, 13, 14, 5, 6, 3, 4, 1, 2, 7, 8, 9, 10, 11, 12, 33, 34,\n",
    "                  15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 32, 25, 26, 23, 24, 21, 22]]\n",
    "df.rename(columns={0:'spine_X', 1:'spine_Y'}, inplace=True)\n",
    "df.iloc[:, 0] = TRAIN_ROOT_PATH + f'/images/' + df.iloc[:, 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hyperparameter, Config, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of device : 2\n"
     ]
    }
   ],
   "source": [
    "### Multi GPU ###\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of device : {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "### config ###\n",
    "y_col = ['l ankle_X', 'l ankle_Y', 'r knee_X', 'r knee_Y', 'r hip_X',\n",
    "       'r hip_Y', 'pelvis_X', 'pelvis_Y', 'r ankle_X', 'r ankle_Y', 'l hip_X',\n",
    "       'l hip_Y', 'l knee_X', 'l knee_Y', 'spine_X', 'spine_Y', 'thorax_X',\n",
    "       'thorax_Y', 'upper neck_X', 'upper neck_Y', 'head top_X', 'head top_Y',\n",
    "       'r shoulder_X', 'r shoulder_Y', 'r elbow_X', 'r elbow_Y', 'r wrist_X',\n",
    "       'r wrist_Y', 'l wrist_X', 'l wrist_Y', 'l elbow_X', 'l elbow_Y',\n",
    "       'l shoulder_X', 'l shoulder_Y']\n",
    "\n",
    "### Hyperparameter ###\n",
    "EPOCHS = 1000\n",
    "initial_epoch = 0\n",
    "learning_rate = 0.001\n",
    "test_size = 0.3\n",
    "target_size = (256, 256 ,3)\n",
    "batch_size = 1\n",
    "dropout_rate = 0.2\n",
    "\n",
    "patience = 10 # Early Stop patience\n",
    "\n",
    "### Callback ###\n",
    "# Tensorboard\n",
    "logdir = os.path.join('logs', datetime.now().strftime(f'%Y%m%d-%H%M%S'))\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    logdir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    ")\n",
    "\n",
    "# Learningrate scheduler\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10: return 0.001\n",
    "    else: return 0.001 * math.exp(0.1 * (10 - epoch))\n",
    "learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_dir = f'chechpoints'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    ckpt_dir,\n",
    "    monitor='mse',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# Early stop\n",
    "early_stop = tf.keras.callbacks.EarlyStopping('mse', patience=patience, verbose=1)\n",
    "\n",
    "callbacks = [tensorboard, checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(df, test_size=test_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12160 validated image filenames.\n",
      "Found 5212 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='NAME',\n",
    "    y_col=y_col,\n",
    "    target_size=target_size[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='multi_output',\n",
    "    shuffle=True,\n",
    "\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df,\n",
    "    x_col='NAME',\n",
    "    y_col=y_col,\n",
    "    traget_size=target_size[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='multi_output',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define Train, Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define Model, loss ftn, optimizer, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import posenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "model = posenet.load_model('mobilenet_v1')\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanSquaredError(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanSquaredError(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(validation_generator))\n",
    "with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions[-1][0].reshape(34, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobile_net_v1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 8, 8, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  9438208   \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You tried to call `count_params` on conv2d_transpose_1, but the layer isn't built. You can build it manually via: `conv2d_transpose_1.build(batch_input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/posenet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2357\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                               print_fn=print_fn)\n\u001b[0m\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/posenet/lib/python3.6/site-packages/tensorflow/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/posenet/lib/python3.6/site-packages/tensorflow/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/posenet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2157\u001b[0m                          \u001b[0;34m', but the layer isn\\'t built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m                          \u001b[0;34m'You can build it manually via: `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[1;32m   2160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You tried to call `count_params` on conv2d_transpose_1, but the layer isn't built. You can build it manually via: `conv2d_transpose_1.build(batch_input_shape)`."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posenet",
   "language": "python",
   "name": "posenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
