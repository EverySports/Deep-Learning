{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Library & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random, os, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import posenet\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "batch_size = 8\n",
    "mode = 'mobilenet_v1'\n",
    "EPOCHS = 10\n",
    "\n",
    "alpha = .25\n",
    "gamma = 2\n",
    "\n",
    "ckpt_path = '20200820_more_deep_layer-verification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>pelvis_X</th>\n",
       "      <th>pelvis_Y</th>\n",
       "      <th>r hip_X</th>\n",
       "      <th>r hip_Y</th>\n",
       "      <th>r knee_X</th>\n",
       "      <th>r knee_Y</th>\n",
       "      <th>r ankle_X</th>\n",
       "      <th>r ankle_Y</th>\n",
       "      <th>l hip_X</th>\n",
       "      <th>l hip_Y</th>\n",
       "      <th>l knee_X</th>\n",
       "      <th>l knee_Y</th>\n",
       "      <th>l ankle_X</th>\n",
       "      <th>l ankle_Y</th>\n",
       "      <th>spine_X</th>\n",
       "      <th>spine_Y</th>\n",
       "      <th>thorax_X</th>\n",
       "      <th>thorax_Y</th>\n",
       "      <th>upper neck_X</th>\n",
       "      <th>upper neck_Y</th>\n",
       "      <th>head top_X</th>\n",
       "      <th>head top_Y</th>\n",
       "      <th>l shoulder_X</th>\n",
       "      <th>l shoulder_Y</th>\n",
       "      <th>l elbow_X</th>\n",
       "      <th>l elbow_Y</th>\n",
       "      <th>l wrist_X</th>\n",
       "      <th>l wrist_Y</th>\n",
       "      <th>r shoulder_X</th>\n",
       "      <th>r shoulder_Y</th>\n",
       "      <th>r elbow_X</th>\n",
       "      <th>r elbow_Y</th>\n",
       "      <th>r wrist_X</th>\n",
       "      <th>r wrist_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/01560...</td>\n",
       "      <td>610</td>\n",
       "      <td>187</td>\n",
       "      <td>573</td>\n",
       "      <td>185</td>\n",
       "      <td>616</td>\n",
       "      <td>269</td>\n",
       "      <td>620</td>\n",
       "      <td>394</td>\n",
       "      <td>647</td>\n",
       "      <td>188</td>\n",
       "      <td>661</td>\n",
       "      <td>221</td>\n",
       "      <td>656</td>\n",
       "      <td>231</td>\n",
       "      <td>628</td>\n",
       "      <td>181</td>\n",
       "      <td>647</td>\n",
       "      <td>176</td>\n",
       "      <td>637.0201</td>\n",
       "      <td>189.8183</td>\n",
       "      <td>695.9799</td>\n",
       "      <td>108.1817</td>\n",
       "      <td>692</td>\n",
       "      <td>185</td>\n",
       "      <td>693</td>\n",
       "      <td>240</td>\n",
       "      <td>688</td>\n",
       "      <td>313</td>\n",
       "      <td>601</td>\n",
       "      <td>167</td>\n",
       "      <td>553</td>\n",
       "      <td>161</td>\n",
       "      <td>606</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/01559...</td>\n",
       "      <td>763</td>\n",
       "      <td>568</td>\n",
       "      <td>806</td>\n",
       "      <td>543</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>720</td>\n",
       "      <td>593</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>723</td>\n",
       "      <td>429</td>\n",
       "      <td>683</td>\n",
       "      <td>290</td>\n",
       "      <td>682.0000</td>\n",
       "      <td>256.0000</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>68.0000</td>\n",
       "      <td>719</td>\n",
       "      <td>299</td>\n",
       "      <td>711</td>\n",
       "      <td>516</td>\n",
       "      <td>545</td>\n",
       "      <td>466</td>\n",
       "      <td>647</td>\n",
       "      <td>281</td>\n",
       "      <td>555</td>\n",
       "      <td>410</td>\n",
       "      <td>563</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/00580...</td>\n",
       "      <td>974</td>\n",
       "      <td>446</td>\n",
       "      <td>908</td>\n",
       "      <td>438</td>\n",
       "      <td>816</td>\n",
       "      <td>510</td>\n",
       "      <td>804</td>\n",
       "      <td>711</td>\n",
       "      <td>1040</td>\n",
       "      <td>454</td>\n",
       "      <td>906</td>\n",
       "      <td>528</td>\n",
       "      <td>883</td>\n",
       "      <td>707</td>\n",
       "      <td>979</td>\n",
       "      <td>349</td>\n",
       "      <td>985</td>\n",
       "      <td>253</td>\n",
       "      <td>982.7591</td>\n",
       "      <td>235.9694</td>\n",
       "      <td>962.2409</td>\n",
       "      <td>80.0306</td>\n",
       "      <td>1067</td>\n",
       "      <td>253</td>\n",
       "      <td>1167</td>\n",
       "      <td>353</td>\n",
       "      <td>1142</td>\n",
       "      <td>478</td>\n",
       "      <td>902</td>\n",
       "      <td>253</td>\n",
       "      <td>798</td>\n",
       "      <td>340</td>\n",
       "      <td>869</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/08661...</td>\n",
       "      <td>248</td>\n",
       "      <td>341</td>\n",
       "      <td>201</td>\n",
       "      <td>340</td>\n",
       "      <td>305</td>\n",
       "      <td>375</td>\n",
       "      <td>301</td>\n",
       "      <td>461</td>\n",
       "      <td>294</td>\n",
       "      <td>342</td>\n",
       "      <td>335</td>\n",
       "      <td>370</td>\n",
       "      <td>331</td>\n",
       "      <td>455</td>\n",
       "      <td>263</td>\n",
       "      <td>302</td>\n",
       "      <td>279</td>\n",
       "      <td>263</td>\n",
       "      <td>277.0210</td>\n",
       "      <td>268.7786</td>\n",
       "      <td>305.9790</td>\n",
       "      <td>184.2214</td>\n",
       "      <td>314</td>\n",
       "      <td>264</td>\n",
       "      <td>327</td>\n",
       "      <td>320</td>\n",
       "      <td>362</td>\n",
       "      <td>346</td>\n",
       "      <td>244</td>\n",
       "      <td>261</td>\n",
       "      <td>260</td>\n",
       "      <td>335</td>\n",
       "      <td>328</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../Datasets/mpii_human_pose_v1/images/06011...</td>\n",
       "      <td>904</td>\n",
       "      <td>237</td>\n",
       "      <td>865</td>\n",
       "      <td>248</td>\n",
       "      <td>896</td>\n",
       "      <td>318</td>\n",
       "      <td>980</td>\n",
       "      <td>322</td>\n",
       "      <td>943</td>\n",
       "      <td>226</td>\n",
       "      <td>948</td>\n",
       "      <td>290</td>\n",
       "      <td>881</td>\n",
       "      <td>349</td>\n",
       "      <td>881</td>\n",
       "      <td>186</td>\n",
       "      <td>858</td>\n",
       "      <td>135</td>\n",
       "      <td>871.1877</td>\n",
       "      <td>180.4244</td>\n",
       "      <td>835.8123</td>\n",
       "      <td>58.5756</td>\n",
       "      <td>923</td>\n",
       "      <td>123</td>\n",
       "      <td>995</td>\n",
       "      <td>163</td>\n",
       "      <td>961</td>\n",
       "      <td>223</td>\n",
       "      <td>792</td>\n",
       "      <td>147</td>\n",
       "      <td>754</td>\n",
       "      <td>247</td>\n",
       "      <td>772</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NAME  pelvis_X  pelvis_Y  \\\n",
       "0  ../../Datasets/mpii_human_pose_v1/images/01560...       610       187   \n",
       "1  ../../Datasets/mpii_human_pose_v1/images/01559...       763       568   \n",
       "2  ../../Datasets/mpii_human_pose_v1/images/00580...       974       446   \n",
       "3  ../../Datasets/mpii_human_pose_v1/images/08661...       248       341   \n",
       "4  ../../Datasets/mpii_human_pose_v1/images/06011...       904       237   \n",
       "\n",
       "   r hip_X  r hip_Y  r knee_X  r knee_Y  r ankle_X  r ankle_Y  l hip_X  \\\n",
       "0      573      185       616       269        620        394      647   \n",
       "1      806      543        -1        -1         -1         -1      720   \n",
       "2      908      438       816       510        804        711     1040   \n",
       "3      201      340       305       375        301        461      294   \n",
       "4      865      248       896       318        980        322      943   \n",
       "\n",
       "   l hip_Y  l knee_X  l knee_Y  l ankle_X  l ankle_Y  spine_X  spine_Y  \\\n",
       "0      188       661       221        656        231      628      181   \n",
       "1      593        -1        -1         -1         -1      723      429   \n",
       "2      454       906       528        883        707      979      349   \n",
       "3      342       335       370        331        455      263      302   \n",
       "4      226       948       290        881        349      881      186   \n",
       "\n",
       "   thorax_X  thorax_Y  upper neck_X  upper neck_Y  head top_X  head top_Y  \\\n",
       "0       647       176      637.0201      189.8183    695.9799    108.1817   \n",
       "1       683       290      682.0000      256.0000    676.0000     68.0000   \n",
       "2       985       253      982.7591      235.9694    962.2409     80.0306   \n",
       "3       279       263      277.0210      268.7786    305.9790    184.2214   \n",
       "4       858       135      871.1877      180.4244    835.8123     58.5756   \n",
       "\n",
       "   l shoulder_X  l shoulder_Y  l elbow_X  l elbow_Y  l wrist_X  l wrist_Y  \\\n",
       "0           692           185        693        240        688        313   \n",
       "1           719           299        711        516        545        466   \n",
       "2          1067           253       1167        353       1142        478   \n",
       "3           314           264        327        320        362        346   \n",
       "4           923           123        995        163        961        223   \n",
       "\n",
       "   r shoulder_X  r shoulder_Y  r elbow_X  r elbow_Y  r wrist_X  r wrist_Y  \n",
       "0           601           167        553        161        606        217  \n",
       "1           647           281        555        410        563        296  \n",
       "2           902           253        798        340        869        214  \n",
       "3           244           261        260        335        328        354  \n",
       "4           792           147        754        247        772        294  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_ROOT_PATH = f'../../Datasets/mpii_human_pose_v1'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ = pd.read_csv(TRAIN_ROOT_PATH + f'/mpii_human_pose_v1_u12_2/mpii_dataset.csv')\n",
    "df_ = df_.iloc[:, 1:-3]\n",
    "\n",
    "df_ = df_.iloc[:, [0, 13, 14, 5, 6, 3, 4, 1, 2, 7, 8, 9, 10, 11, 12,\n",
    "                  15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 32, 25, 26, 23, 24, 21, 22]]\n",
    "\n",
    "spine = (np.array(df_.iloc[:, [15, 16]]) +  np.array(df_.iloc[:, [1, 2]])) // 2\n",
    "\n",
    "df_ = pd.concat([df_, pd.DataFrame(spine)], axis=1)\n",
    "df = df_.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
    "                 33, 34, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]]\n",
    "df.rename(columns={0:'spine_X', 1:'spine_Y'}, inplace=True)\n",
    "\n",
    "df = df.drop(df[df.iloc[:, 1] == -1].index)\n",
    "df = df.drop(df[df.iloc[:, 17] == -1].index)\n",
    "\n",
    "df.iloc[:, 0] = TRAIN_ROOT_PATH + f'/images/' + df.iloc[:, 0]\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train & test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(df, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    mean = [0.40789655, 0.44719303, 0.47026116]\n",
    "    std = [0.2886383, 0.27408165, 0.27809834]\n",
    "    return ((np.float32(image) / 255.) - mean) / std\n",
    "\n",
    "def heatmap(keypoints, input_size, output_width=32, output_height=32, sigma=1):\n",
    "    \n",
    "    heatmap_result = np.zeros((output_width, output_height, 17))\n",
    "    offset_result = np.zeros((output_width, output_height, 34))\n",
    "    displacement_fwd_result = np.zeros((output_width, output_height, 32))\n",
    "    displacement_bwd_result = np.zeros((output_width, output_height, 32))\n",
    "    resize_rate_w = output_width / input_size[1]\n",
    "    resize_rate_h = output_height / input_size[0]\n",
    "    \n",
    "    def get_coords(keypoints):\n",
    "        keypoints = keypoints.reshape(17, 2)\n",
    "        x_radius = (np.max(keypoints[:,0]) - np.min(keypoints[:,0])) / 8\n",
    "        y_radius = (np.max(keypoints[:,1]) - np.min(keypoints[:,1])) / 8\n",
    "        return keypoints, x_radius, y_radius\n",
    "    \n",
    "    def get_heatmap(p_x, p_y, sigma):\n",
    "        X1 = np.linspace(1, output_width, output_height)\n",
    "        Y1 = np.linspace(1, output_width, output_height)\n",
    "        [X, Y] = np.meshgrid(X1, Y1)\n",
    "        X = X - floor(p_x)\n",
    "        Y = Y - floor(p_y)\n",
    "        D2 = X * X + Y * Y\n",
    "        E2 = 2.0 * sigma ** 2\n",
    "        Exponent = D2 / E2\n",
    "        heatmap = np.exp(-Exponent)\n",
    "        heatmap = heatmap[:, :, np.newaxis]\n",
    "        return heatmap\n",
    "    \n",
    "    def get_offset(x, y, x_radius, y_radius):\n",
    "        x_radius = np.max([2, floor(x_radius * resize_rate_h)])\n",
    "        y_radius = np.max([2, floor(y_radius * resize_rate_w)])\n",
    "        offset_x = np.zeros((output_width, output_height))\n",
    "        offset_y = np.zeros((output_width, output_height))\n",
    "        p_x = floor(x * resize_rate_w)\n",
    "        p_y = floor(y * resize_rate_h)\n",
    "        for idx in range(output_width):\n",
    "            # offset_x[idx,:] = x - (p_x / resize_rate_w) + (1 / resize_rate_w) * (idx - p_x)\n",
    "            # offset_y[:,idx] = y - (p_y / resize_rate_h) + (1 / resize_rate_h) * (idx - p_y)\n",
    "            if p_y - y_radius <= idx <= p_y + y_radius:\n",
    "                offset_x[idx,p_x - x_radius:p_x + x_radius] = y - idx / resize_rate_h\n",
    "            if p_x - x_radius <= idx <= p_x + x_radius:\n",
    "                offset_y[p_y - y_radius:p_y + y_radius,idx] = x - idx / resize_rate_w\n",
    "        return offset_x, offset_y\n",
    "    \n",
    "    keypoints, x_radius, y_radius = get_coords(keypoints)\n",
    "    \n",
    "    for idx, keypoint in enumerate(keypoints):\n",
    "        if -1 in keypoint: continue\n",
    "        heatmap = get_heatmap(keypoint[0] * resize_rate_w,\n",
    "                              keypoint[1] * resize_rate_h,\n",
    "                              sigma)\n",
    "        heatmap_result[:,:,idx] = np.maximum(heatmap_result[:,:,idx], heatmap[:,:,0])\n",
    "        \n",
    "        offset_x, offset_y = get_offset(keypoint[0], keypoint[1], x_radius, y_radius)\n",
    "        offset_result[:,:,idx] = offset_x\n",
    "        offset_result[:,:,17 + idx] = offset_y\n",
    "    \n",
    "    return heatmap_result, offset_result, displacement_fwd_result, displacement_bwd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap(batch, heatmap_result, offset_result, displacement_fwd_result=None, displacement_bwd_result=None):\n",
    "        \n",
    "    plt.figure(figsize=(10, 30))\n",
    "\n",
    "    ### Heatmap\n",
    "    for idx in range(17):\n",
    "        plt.subplot(12,5,idx+1)\n",
    "        plt.imshow(heatmap_result[batch][:,:,idx])\n",
    "        plt.title(idx)\n",
    "\n",
    "    \n",
    "    ### Offset\n",
    "    for idx in range(17):\n",
    "        plt.subplot(12,5,idx+1+20)\n",
    "        plt.imshow(offset_result[batch][:,:,idx])\n",
    "        plt.colorbar()\n",
    "        plt.title(idx)\n",
    "        plt.subplot(12,5,idx+18+20)\n",
    "        plt.imshow(offset_result[batch][:,:,17+idx])\n",
    "        plt.colorbar()\n",
    "        plt.title(17+idx)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datagenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, df, batch_size=4, shuffle=True,\n",
    "                 random_state=42, image_paths=None, mode='fit',):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.image_paths = image_paths\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        list_IDs_batch = [self.list_IDs[i] for i in indexes]\n",
    "\n",
    "        X, img_hs, img_ws = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch, img_hs, img_ws)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "        \n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        X = []\n",
    "        img_ws = []\n",
    "        img_hs = []\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            img_path = self.image_paths[ID]\n",
    "            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "            img /= 255.\n",
    "            img_hs.append(img.shape[0])\n",
    "            img_ws.append(img.shape[1])\n",
    "            \n",
    "            ### Show Img ###\n",
    "            # plt.imshow(img)\n",
    "            # plt.title(f'ID: {ID}, Shape: {img.shape}')\n",
    "            ################\n",
    "            img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            X.append(img)\n",
    "        X = np.array(X)\n",
    "        return X, img_hs, img_ws\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch, img_hs, img_ws):\n",
    "        heatmap_result = []\n",
    "        offset_result = []\n",
    "        displacement_fwd_result = []\n",
    "        displacement_bwd_result = []\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            keypoints = df[df.index == ID].iloc[:, 1:].to_numpy()[0]\n",
    "            hm, offset, _, _ = heatmap(keypoints, input_size=(img_hs[i], img_ws[i]))\n",
    "            heatmap_result.append(hm)\n",
    "            offset_result.append(offset)\n",
    "            # displacement_fwd_result.append(displacement_fwd)\n",
    "            # displacement_bwd_result.append(displacement_bwd)\n",
    "            \n",
    "        heatmap_result = np.array(heatmap_result)\n",
    "        offset_result = np.array(offset_result)\n",
    "        # displacement_fwd_result = np.array(displacement_fwd_result)\n",
    "        # displacement_bwd_result = np.array(displacement_bwd_result)\n",
    "        \n",
    "#         return [heatmap_result, offset_result, displacement_fwd_result, displacement_bwd_result]\n",
    "        return [heatmap_result, offset_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    base_model = posenet.load_model(mode)\n",
    "    inputs = tf.keras.Input(shape=(256,256,3))\n",
    "    outputs = base_model(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Swing Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaptiveSwingLoss(y_pred, y_true, alpha=2.1, omega=14, epsilon=1, theta=0.5):\n",
    "    # lossMat = tf.zeros_like(y_pred)\n",
    "    A = omega * (1/(1+(theta/epsilon)**(alpha-y_true)))*(alpha-y_true)*((theta/epsilon)**(alpha-y_true-1))/epsilon\n",
    "    C = theta*A - omega*tf.math.log(1+(theta/epsilon)**(alpha-y_true))\n",
    "    C = tf.cast(C, dtype=tf.float32)\n",
    "    case1_ind = tf.math.abs(y_true - y_pred) < theta\n",
    "    case2_ind = tf.math.abs(y_true - y_pred) >= theta\n",
    "    result_1 = omega*tf.math.log(1+tf.math.abs((y_true[case1_ind]-y_pred[case1_ind])/epsilon)**(alpha-y_true[case1_ind]))\n",
    "    result_2 = A[case2_ind]*tf.math.abs(y_true[case2_ind]-y_pred[case2_ind]) - C[case2_ind]\n",
    "    result = tf.reduce_mean(result_1) + tf.reduce_mean(result_2)\n",
    "    return result\n",
    "\n",
    "def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "    \n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b \n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
    "\n",
    "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "    # or reduce_sum and/or axis=-1\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def criterion(y_true, y_pred): # Regression Loss\n",
    "\n",
    "    # regr_loss = mean_squared_error(y_true, y_pred)\n",
    "    regr_loss = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "    loss = tf.reduce_mean(regr_loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def criterion2(y_true, y_pred): # Heatmap Loss\n",
    "    \n",
    "    loss = focal_loss(y_true, y_pred)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    # loss = [tf.keras.losses.MeanAbsoluteError(),\n",
    "    #        tf.keras.losses.MeanAbsoluteError()],\n",
    "    # loss = [AdaptiveSwingLoss, criterion],\n",
    "    # loss = [criterion2, criterion],\n",
    "    loss = [criterion2, tf.keras.losses.MeanAbsoluteError()],\n",
    "    loss_weights = [10, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = 4\n",
    "train_gen_test = DataGenerator(\n",
    "    list_IDs = train_df.index,\n",
    "    df = df,\n",
    "    batch_size = bs,\n",
    "    shuffle = False,\n",
    "    image_paths = train_df['NAME'],\n",
    "    mode = 'fit',\n",
    ")\n",
    "\n",
    "img, regr = train_gen_test.__getitem__(1)\n",
    "result = model(img)\n",
    "# draw_heatmap(bs-1, *regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    list_IDs = train_df.index,\n",
    "    df = df,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    image_paths = train_df['NAME'],\n",
    "    mode = 'fit',\n",
    ")\n",
    "\n",
    "val_gen = DataGenerator(\n",
    "    list_IDs = validation_df.index,\n",
    "    df = df,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    image_paths = validation_df['NAME'],\n",
    "    mode = 'fit',\n",
    ")\n",
    "\n",
    "ckpt = ModelCheckpoint(\n",
    "    filepath = f'./checkpoints/{ckpt_path}.hdf5',\n",
    "    monitor = 'loss',\n",
    "    verbose = 0,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    mode = 'auto'\n",
    ")\n",
    "\n",
    "reducelr = ReduceLROnPlateau(\n",
    "    monitor = 'loss',\n",
    "    factor = .25,\n",
    "    patience = 2,\n",
    "    min_lr = 1e-5,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   2/1471 [..............................] - ETA: 1:50 - loss: 2.1422 - mobile_net_v1_loss: 0.0842 - mobile_net_v1_1_loss: 1.3000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0486s vs `on_train_batch_end` time: 0.1012s). Check your callbacks.\n",
      "1471/1471 [==============================] - 381s 259ms/step - loss: 1.1798 - mobile_net_v1_loss: 0.0024 - mobile_net_v1_1_loss: 1.1554 - val_loss: 1.1739 - val_mobile_net_v1_loss: 0.0020 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 2/10\n",
      "1471/1471 [==============================] - 380s 258ms/step - loss: 1.1734 - mobile_net_v1_loss: 0.0019 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1734 - val_mobile_net_v1_loss: 0.0020 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 3/10\n",
      "1471/1471 [==============================] - 377s 256ms/step - loss: 1.1717 - mobile_net_v1_loss: 0.0017 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1734 - val_mobile_net_v1_loss: 0.0020 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 4/10\n",
      "1471/1471 [==============================] - 378s 257ms/step - loss: 1.1703 - mobile_net_v1_loss: 0.0016 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1741 - val_mobile_net_v1_loss: 0.0020 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 5/10\n",
      "1471/1471 [==============================] - 378s 257ms/step - loss: 1.1694 - mobile_net_v1_loss: 0.0015 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1733 - val_mobile_net_v1_loss: 0.0020 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 6/10\n",
      "1471/1471 [==============================] - 376s 256ms/step - loss: 1.1687 - mobile_net_v1_loss: 0.0015 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1779 - val_mobile_net_v1_loss: 0.0024 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 7/10\n",
      "1471/1471 [==============================] - 376s 256ms/step - loss: 1.1682 - mobile_net_v1_loss: 0.0014 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1777 - val_mobile_net_v1_loss: 0.0024 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 8/10\n",
      "1471/1471 [==============================] - 376s 256ms/step - loss: 1.1678 - mobile_net_v1_loss: 0.0014 - mobile_net_v1_1_loss: 1.1542 - val_loss: 1.1770 - val_mobile_net_v1_loss: 0.0023 - val_mobile_net_v1_1_loss: 1.1536\n",
      "Epoch 9/10\n",
      " 449/1471 [========>.....................] - ETA: 3:04 - loss: 1.1644 - mobile_net_v1_loss: 0.0013 - mobile_net_v1_1_loss: 1.1512"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [reducelr, ckpt],\n",
    "    use_multiprocessing = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "best = min(history.history['val_loss'])\n",
    "plt.title(f'Best Loss : {best}')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = posenet.load_model(mode)\n",
    "inputs = tf.keras.Input(shape=(256,256,3))\n",
    "outputs = base_model(inputs)\n",
    "inf_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "inf_model.load_weights(f'./checkpoints/{ckpt_path}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_gen = DataGenerator(\n",
    "    list_IDs = validation_df.index,\n",
    "    df = df,\n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    image_paths = validation_df['NAME'],\n",
    "    mode = 'fit',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, regr = inf_gen.__getitem__(1)\n",
    "result = inf_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_heatmap(0, *regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_heatmap(0, heatmap_result=result[0], offset_result=result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posenet",
   "language": "python",
   "name": "posenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
